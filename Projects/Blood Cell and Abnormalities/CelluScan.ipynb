{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fa6e425",
   "metadata": {},
   "source": [
    "# CelluScan ðŸ§«\n",
    "\n",
    "CelluScan is a deep learning classification model designed to classify blood cells, mainly white blood cells, and detect abnormalities.\n",
    "\n",
    "This notebook covers the full pipeline from data cleaning and augmentation, through dataloader creation, to model training and evaluation.\n",
    "\n",
    "## Features\n",
    "\n",
    "- **Classifies multiple blood cell types** (e.g., Neutrophil, Lymphocyte, Monocyte, etc.)\n",
    "- **Handles class imbalance** via augmentation\n",
    "- **Easily extensible** for new classes or abnormality detection\n",
    "\n",
    "## Workflow Overview\n",
    "\n",
    "1. Data cleaning and balancing\n",
    "2. Data augmentation for minority classes\n",
    "3. Dataloader creation and splitting\n",
    "4. Model training and evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6450c344",
   "metadata": {},
   "source": [
    "## 0. Imports & Colors\n",
    "\n",
    "We import all necessary libraries for data handling, augmentation, and model building.\n",
    "\n",
    "We also define a set of ANSI color codes for improved terminal output readability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b46b2a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "CUDA devices: 1\n",
      "Current device: 0\n",
      "Device name: NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from going_modular.GPU_check import GPU_check\n",
    "\n",
    "# ANSI escape codes for colors in Python\n",
    "colors = {\n",
    "    \"reset\": \"\\033[0m\",\n",
    "\n",
    "    # Regular Colors\n",
    "    \"black\": \"\\033[30m\",\n",
    "    \"red\": \"\\033[31m\",\n",
    "    \"green\": \"\\033[32m\",\n",
    "    \"yellow\": \"\\033[33m\",\n",
    "    \"blue\": \"\\033[34m\",\n",
    "    \"magenta\": \"\\033[35m\",\n",
    "    \"cyan\": \"\\033[36m\",\n",
    "    \"white\": \"\\033[37m\",\n",
    "\n",
    "    # Bright Colors\n",
    "    \"bright_black\": \"\\033[90m\",\n",
    "    \"bright_red\": \"\\033[91m\",\n",
    "    \"bright_green\": \"\\033[92m\",\n",
    "    \"bright_yellow\": \"\\033[93m\",\n",
    "    \"bright_blue\": \"\\033[94m\",\n",
    "    \"bright_magenta\": \"\\033[95m\",\n",
    "    \"bright_cyan\": \"\\033[96m\",\n",
    "    \"bright_white\": \"\\033[97m\",\n",
    "\n",
    "    # Background Colors\n",
    "    \"bg_black\": \"\\033[40m\",\n",
    "    \"bg_red\": \"\\033[41m\",\n",
    "    \"bg_green\": \"\\033[42m\",\n",
    "    \"bg_yellow\": \"\\033[43m\",\n",
    "    \"bg_blue\": \"\\033[44m\",\n",
    "    \"bg_magenta\": \"\\033[45m\",\n",
    "    \"bg_cyan\": \"\\033[46m\",\n",
    "    \"bg_white\": \"\\033[47m\",\n",
    "\n",
    "    # Bright Backgrounds\n",
    "    \"bg_bright_black\": \"\\033[100m\",\n",
    "    \"bg_bright_red\": \"\\033[101m\",\n",
    "    \"bg_bright_green\": \"\\033[102m\",\n",
    "    \"bg_bright_yellow\": \"\\033[103m\",\n",
    "    \"bg_bright_blue\": \"\\033[104m\",\n",
    "    \"bg_bright_magenta\": \"\\033[105m\",\n",
    "    \"bg_bright_cyan\": \"\\033[106m\",\n",
    "    \"bg_bright_white\": \"\\033[107m\",\n",
    "\n",
    "    # Styles\n",
    "    \"bold\": \"\\033[1m\",\n",
    "    \"dim\": \"\\033[2m\",\n",
    "    \"italic\": \"\\033[3m\",\n",
    "    \"underline\": \"\\033[4m\",\n",
    "    \"blink\": \"\\033[5m\",\n",
    "    \"reverse\": \"\\033[7m\",\n",
    "    \"hidden\": \"\\033[8m\"\n",
    "}\n",
    "\n",
    "device = GPU_check()\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd3dd6e",
   "metadata": {},
   "source": [
    "## 1. Cleaning the Data\n",
    "\n",
    "### Initial Collected Data\n",
    "\n",
    "Below is the class distribution in the raw dataset:\n",
    "\n",
    "| Class Name           | Count |\n",
    "| -------------------- | ----- |\n",
    "| Immature Granulocyte | 151   |\n",
    "| Promyelocytes        | 592   |\n",
    "| Myeloblast           | 1,000 |\n",
    "| Metamyelocytes       | 1,015 |\n",
    "| Myelocytes           | 1,137 |\n",
    "| Erythroblast         | 1,551 |\n",
    "| Band Neutrophil      | 1,634 |\n",
    "| Basophil             | 1,653 |\n",
    "| Platlets             | 2,348 |\n",
    "| Segmented Neutrophil | 2,646 |\n",
    "| Monocyte             | 5,046 |\n",
    "| Neutrophil           | 6,779 |\n",
    "| Eosinophil           | 7,141 |\n",
    "| Lymphocyte           | 8,685 |\n",
    "\n",
    "### Our Goal\n",
    "\n",
    "- **Target:** At least 4,500 samples per class for balanced training.\n",
    "- **How:** Duplicate and augment (using `TrivialAugmentWide`) only for classes below the target.\n",
    "- **Result:** All classes will have at least 4,500 images, improving model robustness and reducing bias.\n",
    "\n",
    "The following code block performs this balancing and augmentation automatically.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0528376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'Band Neutrophil': 3449, 'Basophil': 1653, 'Eosinophil': 7141, 'Erythroblast': 1551, 'Immature Granulocyte': 151, 'Lymphocyte': 8685, 'Metamyelocytes': 1015, 'Monocyte': 5046, 'Myeloblast': 1000, 'Myelocytes': 1137, 'Neutrophil': 6779, 'Platelets': 2348, 'Promyelocytes': 592, 'Segmented Neutrophil': 2646})\n",
      "\n",
      "\u001b[32m[INFO] Starting augmentation...\u001b[0m\n",
      "Augmenting Band Neutrophil: current=3449, generating=1051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1051/1051 [00:09<00:00, 113.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting Basophil: current=1653, generating=2847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2847/2847 [00:22<00:00, 127.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting Erythroblast: current=1551, generating=2949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2949/2949 [00:22<00:00, 132.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting Immature Granulocyte: current=151, generating=4349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4349/4349 [00:13<00:00, 324.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting Metamyelocytes: current=1015, generating=3485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3485/3485 [00:17<00:00, 202.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting Myeloblast: current=1000, generating=3500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3500/3500 [00:17<00:00, 200.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting Myelocytes: current=1137, generating=3363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3363/3363 [00:15<00:00, 212.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting Platelets: current=2348, generating=2152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2152/2152 [00:19<00:00, 110.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting Promyelocytes: current=592, generating=3908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3908/3908 [00:19<00:00, 198.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting Segmented Neutrophil: current=2646, generating=1854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1854/1854 [00:20<00:00, 90.70it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m[INFO]Augmentation complete. All classes now have at least 4,500 samples.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "# Set paths\n",
    "DATA_DIR = Path(\"Blood cells datasets/\")\n",
    "TARGET_COUNT = 4500 # Target minimum number of samples per class\n",
    "\n",
    "# Define the augmentation transformation\n",
    "augment_transform = transforms.TrivialAugmentWide()\n",
    "\n",
    "# Load dataset\n",
    "base_dataset = ImageFolder(root=DATA_DIR)\n",
    "class_to_idx = base_dataset.class_to_idx # e.g., {\"Basophil\": 0, ...}\n",
    "\n",
    "# Create a mapping from class index to class name\n",
    "idx_to_class = {v: k for k, v in class_to_idx.items()}\n",
    "\n",
    "# Count current number of images in each class\n",
    "from collections import defaultdict\n",
    "class_counts = defaultdict(int) # Creates an empty dictionary to store image counts per class, initialized to 0.\n",
    "for path, label in base_dataset.samples: # loop over every image and retrieves its label\n",
    "    class_name = idx_to_class[label] # Convert label index to class name\n",
    "    class_counts[class_name] += 1  # Increment count for that class\n",
    "\n",
    "# Test print class counts\n",
    "print (class_counts)\n",
    "print(f\"\\n{colors['green']}[INFO] Starting augmentation...{colors['reset']}\")\n",
    "\n",
    "\n",
    "# Loop over classes and duplicate if needed\n",
    "for class_name, count in class_counts.items():\n",
    "    if count >= TARGET_COUNT:\n",
    "        continue  # Already balanced\n",
    "\n",
    "    folder_path = DATA_DIR / class_name\n",
    "    images = list(folder_path.glob(\"*\"))  # All image files in the class folder\n",
    "\n",
    "    to_generate = TARGET_COUNT - count\n",
    "    print(f\"Augmenting {class_name}: current={count}, generating={to_generate}\")\n",
    "\n",
    "    for i in tqdm(range(to_generate)):\n",
    "        # Randomly pick an existing image\n",
    "        src_path = random.choice(images)\n",
    "        with Image.open(src_path) as img:\n",
    "            img = img.convert(\"RGB\")  # ensure consistency\n",
    "            augmented = augment_transform(img)\n",
    "\n",
    "            # Create new file name\n",
    "            base_name = src_path.stem\n",
    "            new_filename = f\"{base_name}_aug{i}.jpg\"\n",
    "            new_path = folder_path / new_filename\n",
    "\n",
    "            # Save\n",
    "            augmented.save(new_path)\n",
    "\n",
    "print(f\"\\n{colors['blue']}[INFO]Augmentation complete. All classes now have at least 4,500 samples.{colors['reset']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23db8f2",
   "metadata": {},
   "source": [
    "## 2. Get Dataloaders\n",
    "\n",
    "After cleaning and balancing the data, we prepare the dataset for model training.\n",
    "\n",
    "### Steps:\n",
    "\n",
    "1. **Resize and transform images** to a consistent shape for model input.\n",
    "2. **Split the dataset** into training (80%) and testing (20%) sets.\n",
    "3. **Create PyTorch dataloaders** for efficient batch processing.\n",
    "\n",
    "This ensures that our model receives well-structured and balanced data for both training and evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "681d03c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset = <torch.utils.data.dataset.Subset object at 0x000001D09CB41480>\n",
      "Testing dataset = <torch.utils.data.dataset.Subset object at 0x000001D09CB43580>\n",
      "Training dataloader = <torch.utils.data.dataloader.DataLoader object at 0x000001D09CE0F820>\n",
      "Testing dataloader = <torch.utils.data.dataloader.DataLoader object at 0x000001D09CE0F130>\n",
      "Class names = ['Band Neutrophil', 'Basophil', 'Eosinophil', 'Erythroblast', 'Immature Granulocyte', 'Lymphocyte', 'Metamyelocytes', 'Monocyte', 'Myeloblast', 'Myelocytes', 'Neutrophil', 'Platelets', 'Promyelocytes', 'Segmented Neutrophil']\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "DATA_DIR = Path(\"Blood cells datasets/\")\n",
    "\n",
    "# Define a transform that resizes all images to the same shape\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Get dataset using ImageFolder\n",
    "dataset = datasets.ImageFolder(\n",
    "    root= DATA_DIR,\n",
    "    transform= transform\n",
    ")\n",
    "\n",
    "# Define train and test lengths (80% train, 20% test)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "# Random split dataset into train and test datasets\n",
    "train_dataset, test_dataset = random_split(dataset, lengths=[train_size, test_size])\n",
    "\n",
    "# Get dataloader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle= True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle= False)\n",
    "\n",
    "# Get class names\n",
    "class_names = dataset.classes\n",
    "\n",
    "print (f\"Training dataset = {train_dataset}\")\n",
    "print (f\"Testing dataset = {test_dataset}\")\n",
    "print (f\"Training dataloader = {train_dataloader}\")\n",
    "print (f\"Testing dataloader = {test_dataloader}\")\n",
    "print (f\"Class names = {class_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528a0986",
   "metadata": {},
   "source": [
    "## 2.1 Using a Subset of the Data\n",
    "\n",
    "For rapid prototyping and to avoid overfitting during early experimentation, we use only 20% of the data from each class.\n",
    "\n",
    "This approach allows for faster training and debugging, especially when working with large datasets.\n",
    "\n",
    "The function below samples 20% of each class and returns a corresponding dataloader.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9de8bd7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x1d09e33b550>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x1d09e33b3d0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, Subset\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "def get_20_percent_dataloader(dataset: torch.utils.data.Dataset, \n",
    "                            batch_size:int =32, \n",
    "                            shuffle:bool =True,\n",
    "                            seed:int =42) -> DataLoader:\n",
    "    \"\"\"\n",
    "    Returns a DataLoader containing 20% of each class from the given dataset.\n",
    "\n",
    "    Args:\n",
    "        dataset (torch.utils.data.Dataset or torch.utils.data.Subset): A dataset object (e.g. ImageFolder or Subset).\n",
    "        batch_size (int): Batch size for the returned DataLoader.\n",
    "        shuffle (bool): Whether to shuffle the DataLoader output.\n",
    "        seed (int): Random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        DataLoader: A PyTorch DataLoader with 20% of each class from the dataset.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "\n",
    "    # Get true targets and indices from base dataset\n",
    "    if isinstance(dataset, Subset):\n",
    "        base_dataset = dataset.dataset\n",
    "        base_indices = dataset.indices\n",
    "        targets = [base_dataset.targets[i] for i in base_indices]\n",
    "    else:\n",
    "        base_dataset = dataset\n",
    "        base_indices = list(range(len(dataset)))\n",
    "        targets = base_dataset.targets\n",
    "        \n",
    "\n",
    "    # Group indices by class label\n",
    "    class_to_idx = defaultdict(list)\n",
    "    for base_idx, label in zip(base_indices, targets):\n",
    "        class_to_idx[label].append(base_idx)\n",
    "\n",
    "    # Sample 20% of each class\n",
    "    selected_indices = []\n",
    "    for label, idxs in class_to_idx.items():\n",
    "        n = max(1, int(0.2 * len(idxs)))\n",
    "        selected_indices.extend(random.sample(idxs, n))\n",
    "\n",
    "    # Create a subset and dataloader\n",
    "    subset = Subset(base_dataset, selected_indices)\n",
    "    dataloader = DataLoader(subset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "\n",
    "# Create dataloaders with 20% of the data in each class (to avoid dropouts)\n",
    "train_dataloader_20_percent = get_20_percent_dataloader(dataset= train_dataset,\n",
    "                                                        batch_size= 32,\n",
    "                                                        shuffle= True)\n",
    "\n",
    "test_dataloader_20_percent = get_20_percent_dataloader(dataset= test_dataset,\n",
    "                                                    batch_size= 32,\n",
    "                                                    shuffle= False)\n",
    "\n",
    "train_dataloader_20_percent, test_dataloader_20_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd9c84dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3, 224, 224]), torch.Size([32]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect one batch\n",
    "images_batch, labels_batch = next(iter(train_dataloader_20_percent))\n",
    "\n",
    "images_batch.shape, labels_batch.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
