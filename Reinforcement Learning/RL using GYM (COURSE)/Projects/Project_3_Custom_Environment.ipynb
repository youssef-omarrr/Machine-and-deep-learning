{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3656affa",
   "metadata": {},
   "source": [
    "## 1. Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a291c6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import Env\n",
    "from gymnasium.spaces import Discrete, Box, Dict, Tuple, MultiBinary, MultiDiscrete\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import vec_frame_stack\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e75677b",
   "metadata": {},
   "source": [
    "## 2. Types of spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12a545d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Discrete(3).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d80c7c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.1809281, 1.4727439, 1.1300299],\n",
       "       [1.1918077, 1.0165738, 1.7082382],\n",
       "       [1.6306828, 1.6222956, 1.8615623]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Box(1, 2, shape=(3, 3)).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a66b0e7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.int64(2),\n",
       " array([[1.8700967, 1.8984876, 1.9108628],\n",
       "        [1.6352034, 1.5672063, 1.7939303],\n",
       "        [1.0130398, 1.2071084, 1.0129813]], dtype=float32))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tuple((Discrete(3), Box(1, 2, shape=(3, 3)))).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "499d36f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'height': np.int64(0), 'speed': array([43.863068], dtype=float32)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dict({'height':Discrete(2), \"speed\":Box(0,100, shape=(1,))}).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6edb0424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0], dtype=int8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MultiBinary(4).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aea08684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10,  2,  1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MultiDiscrete([15, 10, 5]).sample() # [varies between 0:14, 0:9, 0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a74dff",
   "metadata": {},
   "source": [
    "## 3. Building and Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d615a07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main 4 functions in any environment\n",
    "class CustomEnv(Env):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def step(self, action):\n",
    "        pass\n",
    "    def render(self):\n",
    "        pass\n",
    "    def reset (self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d98dc999",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from gymnasium import Env\n",
    "from gymnasium.spaces import Discrete, Box\n",
    "\n",
    "class ShowerEnv(Env):\n",
    "    def __init__(self):\n",
    "        # Actions we can take: down (0), stay (1), up (2)\n",
    "        self.action_space = Discrete(3)\n",
    "        \n",
    "        # Temperature array (1D array of a single float)\n",
    "        self.observation_space = Box(\n",
    "            low=np.array([0.0]), # Use float for consistency\n",
    "            high=np.array([100.0]), # Use float for consistency\n",
    "            dtype=np.float32)\n",
    "        \n",
    "        # Initial state: 1D array containing a random starting temperature\n",
    "        self.state = np.array([38.0 + random.randint(-3, 3)]).astype(np.float32)\n",
    "        \n",
    "        # Set shower length -> episode length\n",
    "        self.shower_length = 60\n",
    "        \n",
    "    # -----------------------------------------------------------\n",
    "    def step(self, action):\n",
    "        # Apply action\n",
    "        # 0 - 1 = -1  -> decrease temp\n",
    "        # 1 - 1 = 0   -> hold\n",
    "        # 2 - 1 = 1   -> increase tmep\n",
    "        \n",
    "        # Note: self.state is a numpy array, so we must add a scalar to the first element\n",
    "        self.state[0] += action - 1 \n",
    "        \n",
    "        # Reduce shower length (episode) by 1 second\n",
    "        self.shower_length -= 1 \n",
    "        \n",
    "        # Get the scalar temperature value for reward calculation\n",
    "        current_temp = self.state[0]\n",
    "        \n",
    "        # Calculate reward\n",
    "        if current_temp >= 37.0 and current_temp <= 39.0: \n",
    "            reward = 5.0 \n",
    "        else: \n",
    "            reward = -1.0 \n",
    "        \n",
    "        # Check if shower is done\n",
    "        terminated = self.shower_length <= 0\n",
    "        truncated = False # Typically used for time limits, set to False here\n",
    "        \n",
    "        # Set placeholder for info\n",
    "        info = {}\n",
    "        \n",
    "        # Return step information (observation, reward, terminated, truncated, info)\n",
    "        return self.state, reward, terminated, truncated, info\n",
    "\n",
    "    # -----------------------------------------------------------\n",
    "    def render(self):\n",
    "        # Implement viz\n",
    "        pass\n",
    "    \n",
    "    # -----------------------------------------------------------\n",
    "    def reset(self, seed=None, options=None):\n",
    "        # *** FIX 1: The correct method signature and super call are needed ***\n",
    "        # Handle seeding (important for SB3 compatibility)\n",
    "        super().reset(seed=seed)\n",
    "        \n",
    "        # Reset shower temperature: Ensure the state is a np.array and the correct dtype\n",
    "        self.state = np.array([38.0 + random.randint(-3, 3)]).astype(np.float32)\n",
    "        \n",
    "        # Reset shower time\n",
    "        self.shower_length = 60 \n",
    "        \n",
    "        # *** FIX 2: Must return both the observation (self.state) AND an info dictionary ***\n",
    "        info = {}\n",
    "        return self.state, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "de0316b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\YOUSSEF\\Desktop\\Codess & Projects\\.venv\\lib\\site-packages\\gymnasium\\spaces\\box.py:236: UserWarning: \u001b[33mWARN: Box low's precision lowered by casting to float32, current low.dtype=float64\u001b[0m\n",
      "  gym.logger.warn(\n",
      "c:\\Users\\YOUSSEF\\Desktop\\Codess & Projects\\.venv\\lib\\site-packages\\gymnasium\\spaces\\box.py:306: UserWarning: \u001b[33mWARN: Box high's precision lowered by casting to float32, current high.dtype=float64\u001b[0m\n",
      "  gym.logger.warn(\n"
     ]
    }
   ],
   "source": [
    "env = ShowerEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cdb5cc63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(0.0, 100.0, (1,), float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b79033a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([56.140285], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "65d7e71f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "833cdfac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754df20f",
   "metadata": {},
   "source": [
    "## 4. Test env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "05ddfade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:-54.0\n",
      "Episode:2 Score:-26.0\n",
      "Episode:3 Score:-48.0\n",
      "Episode:4 Score:-22.0\n",
      "Episode:5 Score:-32.0\n"
     ]
    }
   ],
   "source": [
    "episodes = 5\n",
    "\n",
    "for episode in range(1, episodes+1):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    terminated = False\n",
    "    truncated = False\n",
    "    score = 0\n",
    "    \n",
    "    while not done:\n",
    "        # select a random action from the action space\n",
    "        action = env.action_space.sample()\n",
    "        \n",
    "        # perform that action\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        done = terminated or truncated\n",
    "        \n",
    "        # get score\n",
    "        score += reward\n",
    "        \n",
    "    print('Episode:{} Score:{}'.format(episode, score))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec0b970",
   "metadata": {},
   "source": [
    "## 5. Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a815242a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\YOUSSEF\\Desktop\\Codess & Projects\\.venv\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = PPO('MlpPolicy', env, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06eebb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.learn(total_timesteps=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f297eb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../Training/Saved_Models/PPO_Custom_ENV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "15bc6424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(156.0), np.float64(176.36326148038881))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
