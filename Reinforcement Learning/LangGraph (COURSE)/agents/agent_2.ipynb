{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d1f5654",
   "metadata": {},
   "source": [
    "# Agent 2: AI Agent with memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7c4b558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from typing import TypedDict, List, Union\n",
    "\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10afb9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    # -> the message can be of type HumanMessage or AIMessage\n",
    "    msg: List[Union[HumanMessage, AIMessage]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a1e550",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(model=\"openai/gpt-oss-120b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a1e38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(state: AgentState) -> AgentState:\n",
    "    response = llm.invoke(state[\"msg\"])\n",
    "\n",
    "    state[\"msg\"].append(AIMessage(content=response.content))\n",
    "\n",
    "    print(f\"\\nAI: {response.content}\")\n",
    "    # print(\"CURRENT STATE: \", state[\"msg\"])\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6639c5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(AgentState)\n",
    "graph.add_node(\"process\", process)\n",
    "graph.add_edge(START, \"process\")\n",
    "graph.add_edge(\"process\", END)\n",
    "agent = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2091fb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_history = []  # -> NEW!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4fe0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI: Hello! How can I help you today?\n",
      "[HumanMessage(content='hello', additional_kwargs={}, response_metadata={}), AIMessage(content='Hello! How can I help you today?', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[])]\n",
      "\n",
      "AI: Nice to meet you, Youssef! How can I assist you today?\n",
      "[HumanMessage(content='hello', additional_kwargs={}, response_metadata={}), AIMessage(content='Hello! How can I help you today?', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[]), HumanMessage(content='my name is youssef', additional_kwargs={}, response_metadata={}), AIMessage(content='Nice to meet you, Youssef! How can I assist you today?', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[])]\n",
      "\n",
      "AI: Your name is Youssef.\n",
      "[HumanMessage(content='hello', additional_kwargs={}, response_metadata={}), AIMessage(content='Hello! How can I help you today?', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[]), HumanMessage(content='my name is youssef', additional_kwargs={}, response_metadata={}), AIMessage(content='Nice to meet you, Youssef! How can I assist you today?', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[]), HumanMessage(content='what was my name again?', additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is Youssef.', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[])]\n",
      "\n",
      "AI: I can keep track of details you share **within the same conversation**—like your name, preferences, or any other information you mention while we’re chatting. This helps me give more relevant and coherent responses.\n",
      "\n",
      "However, I don’t have long‑term memory. Once the session ends (or the conversation is reset), I won’t retain any of those details. If you start a new chat, I won’t remember that your name is Youssef unless you tell me again.\n",
      "[HumanMessage(content='hello', additional_kwargs={}, response_metadata={}), AIMessage(content='Hello! How can I help you today?', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[]), HumanMessage(content='my name is youssef', additional_kwargs={}, response_metadata={}), AIMessage(content='Nice to meet you, Youssef! How can I assist you today?', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[]), HumanMessage(content='what was my name again?', additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is Youssef.', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[]), HumanMessage(content='so you can remember things?', additional_kwargs={}, response_metadata={}), AIMessage(content='I can keep track of details you share **within the same conversation**—like your name, preferences, or any other information you mention while we’re chatting. This helps me give more relevant and coherent responses.\\n\\nHowever, I don’t have long‑term memory. Once the session ends (or the conversation is reset), I won’t retain any of those details. If you start a new chat, I won’t remember that your name is Youssef unless you tell me again.', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[])]\n",
      "\n",
      "AI: I’m glad you like it! If there’s anything else you’d like to discuss or any way I can help, just let me know.\n",
      "[HumanMessage(content='hello', additional_kwargs={}, response_metadata={}), AIMessage(content='Hello! How can I help you today?', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[]), HumanMessage(content='my name is youssef', additional_kwargs={}, response_metadata={}), AIMessage(content='Nice to meet you, Youssef! How can I assist you today?', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[]), HumanMessage(content='what was my name again?', additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is Youssef.', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[]), HumanMessage(content='so you can remember things?', additional_kwargs={}, response_metadata={}), AIMessage(content='I can keep track of details you share **within the same conversation**—like your name, preferences, or any other information you mention while we’re chatting. This helps me give more relevant and coherent responses.\\n\\nHowever, I don’t have long‑term memory. Once the session ends (or the conversation is reset), I won’t retain any of those details. If you start a new chat, I won’t remember that your name is Youssef unless you tell me again.', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[]), HumanMessage(content=\"that's great\", additional_kwargs={}, response_metadata={}), AIMessage(content='I’m glad you like it! If there’s anything else you’d like to discuss or any way I can help, just let me know.', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[])]\n"
     ]
    }
   ],
   "source": [
    "user_input = input(\"enter: \")\n",
    "\n",
    "while user_input != \"exit\":\n",
    "    # add user input to history\n",
    "    conv_history.append(HumanMessage(content=user_input))\n",
    "\n",
    "    result = agent.invoke({\n",
    "        \"msg\": conv_history  # -> send the whole history to the llm NOT JUST THE LAST INPUT\n",
    "    })\n",
    "\n",
    "    print(result['msg'])\n",
    "    conv_history = result['msg']\n",
    "\n",
    "    user_input = input(\"enter: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95f6a13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation saved to logging.txt\n"
     ]
    }
   ],
   "source": [
    "with open(\"logging.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(\"Your Conversation Log:\\n\")\n",
    "    file.write(\"=\"*50 + \"\\n\\n\")\n",
    "\n",
    "    for message in conv_history:\n",
    "        if isinstance(message, HumanMessage):\n",
    "            file.write(f\"You: {message.content}\\n\")\n",
    "        elif isinstance(message, AIMessage):\n",
    "            file.write(f\"AI: {message.content}\\n\\n\")\n",
    "\n",
    "    file.write(\"=\"*50)\n",
    "    file.write(\"\\nEnd of Conversation\\n\")\n",
    "    file.write(\"=\"*50 + '\\n\\n')\n",
    "\n",
    "print(\"Conversation saved to logging.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
