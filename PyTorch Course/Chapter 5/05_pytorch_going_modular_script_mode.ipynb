{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93d72cf3",
   "metadata": {},
   "source": [
    "# 05. Going Modular: Part 2 (script mode)\n",
    "\n",
    "This notebook is part 2/2 of section [05. Going Modular](https://www.learnpytorch.io/05_pytorch_going_modular/).\n",
    "\n",
    "For reference, the two parts are:\n",
    "\n",
    "1. [**05. Going Modular: Part 1 (cell mode)**](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/going_modular/05_pytorch_going_modular_cell_mode.ipynb) - this notebook is run as a traditional Jupyter Notebook/Google Colab notebook and is a condensed version of [notebook 04](https://www.learnpytorch.io/04_pytorch_custom_datasets/).\n",
    "2. [**05. Going Modular: Part 2 (script mode)**](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/going_modular/05_pytorch_going_modular_script_mode.ipynb) - this notebook is the same as number 1 but with added functionality to turn each of the major sections into Python scripts, such as, `data_setup.py` and `train.py`.\n",
    "\n",
    "Why two parts?\n",
    "\n",
    "Because sometimes the best way to learn something is to see how it _differs_ from something else.\n",
    "\n",
    "If you run each notebook side-by-side you'll see how they differ and that's where the key learnings are.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a305b1",
   "metadata": {},
   "source": [
    "## What is script mode?\n",
    "\n",
    "**Script mode** uses [Jupyter Notebook cell magic](https://ipython.readthedocs.io/en/stable/interactive/magics.html) (special commands) to turn specific cells into Python scripts.\n",
    "\n",
    "For example if you run the following code in a cell, you'll create a Python file called `hello_world.py`:\n",
    "\n",
    "```\n",
    "%%writefile hello_world.py\n",
    "print(\"hello world, machine learning is fun!\")\n",
    "```\n",
    "\n",
    "You could then run this Python file on the command line with:\n",
    "\n",
    "```\n",
    "python hello_world.py\n",
    "\n",
    ">>> hello world, machine learning is fun!\n",
    "```\n",
    "\n",
    "The main cell magic we're interested in using is `%%writefile`.\n",
    "\n",
    "Putting `%%writefile filename` at the top of a cell in Jupyter or Google Colab will write the contents of that cell to a specified `filename`.\n",
    "\n",
    "> **Question:** Do I have to create Python files like this? Can't I just start directly with a Python file and skip using a Google Colab notebook?\n",
    ">\n",
    "> **Answer:** Yes. This is only _one_ way of creating Python scripts. If you know the kind of script you'd like to write, you could start writing it straight away. But since using Jupyter/Google Colab notebooks is a popular way of starting off data science and machine learning projects, knowing about the `%%writefile` magic command is a handy tip.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36784e17",
   "metadata": {},
   "source": [
    "### PyTorch in the wild\n",
    "\n",
    "For example, if you find a PyTorch project on GitHub, it may be structured in the following way:\n",
    "\n",
    "```\n",
    "pytorch_project/\n",
    "├── pytorch_project/\n",
    "│   ├── data_setup.py\n",
    "│   ├── engine.py\n",
    "│   ├── model.py\n",
    "│   ├── train.py\n",
    "│   └── utils.py\n",
    "├── models/\n",
    "│   ├── model_1.pth\n",
    "│   └── model_2.pth\n",
    "└── data/\n",
    "    ├── data_folder_1/\n",
    "    └── data_folder_2/\n",
    "```\n",
    "\n",
    "Here, the top level directory is called `pytorch_project` but you could call it whatever you want.\n",
    "\n",
    "Inside there's another directory called `pytorch_project` which contains several `.py` files, the purposes of these may be:\n",
    "\n",
    "- `data_setup.py` - a file to prepare data (and download data if needed).\n",
    "- `engine.py` - a file containing various training functions.\n",
    "- `model_builder.py` or `model.py` - a file to create a PyTorch model.\n",
    "- `train.py` - a file to leverage all other files and train a target PyTorch model.\n",
    "- `utils.py` - a file dedicated to helpful utility functions.\n",
    "\n",
    "And the `models` and `data` directories could hold PyTorch models and data files respectively (though due to the size of models and data files, it's unlikely you'll find the _full_ versions of these on GitHub, these directories are present above mainly for demonstration purposes).\n",
    "\n",
    "> **Note:** There are many different ways to structure a Python project and subsequently a PyTorch project. This isn't a guide on _how_ to structure your projects, only an example of how you _might_ come across PyTorch projects in the wild. For more on structuring Python projects, see Real Python's [_Python Application Layouts: A Reference_](https://realpython.com/python-application-layouts/) guide.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3813d835",
   "metadata": {},
   "source": [
    "## What we're going to cover\n",
    "\n",
    "By the end of this notebook you should finish with a directory structure of:\n",
    "\n",
    "```\n",
    "going_modular/\n",
    "├── going_modular/\n",
    "│   ├── data_setup.py\n",
    "│   ├── engine.py\n",
    "│   ├── model_builder.py\n",
    "│   ├── train.py\n",
    "│   └── utils.py\n",
    "├── models/\n",
    "│   ├── 05_going_modular_cell_mode_tinyvgg_model.pth\n",
    "│   └── 05_going_modular_script_mode_tinyvgg_model.pth\n",
    "└── data/\n",
    "    └── pizza_steak_sushi/\n",
    "        ├── train/\n",
    "        │   ├── pizza/\n",
    "        │   │   ├── image01.jpeg\n",
    "        │   │   └── ...\n",
    "        │   ├── steak/\n",
    "        │   └── sushi/\n",
    "        └── test/\n",
    "            ├── pizza/\n",
    "            ├── steak/\n",
    "            └── sushi/\n",
    "```\n",
    "\n",
    "Using this directory structure, you should be able to train a model from within a notebook with the command:\n",
    "\n",
    "```\n",
    "!python going_modular/train.py\n",
    "```\n",
    "\n",
    "Or from the command line with:\n",
    "\n",
    "```\n",
    "python going_modular/train.py\n",
    "```\n",
    "\n",
    "In essence, we will have turned our helpful notebook code into **reusable modular code**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade40966",
   "metadata": {},
   "source": [
    "## 0. Creating a folder for storing Python scripts\n",
    "\n",
    "Since we're going to be creating Python scripts out of our most useful code cells, let's create a folder for storing those scripts.\n",
    "\n",
    "We'll call the folder `going_modular` and create it using Python's [`os.makedirs()`](https://docs.python.org/3/library/os.html) method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5988b2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "going_modular directory exists.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "GOING_MODULAR = Path(\"going_modular/\")\n",
    "if GOING_MODULAR.is_dir():\n",
    "    print(f\"{GOING_MODULAR} directory exists.\")\n",
    "    \n",
    "else:\n",
    "    os.makedirs(\"going_modular\", exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4f76ac",
   "metadata": {},
   "source": [
    "## 1. Get data\n",
    "\n",
    "We're going to start by downloading the same data we used in [notebook 04](https://www.learnpytorch.io/04_pytorch_custom_datasets/#1-get-data), the `pizza_steak_sushi` dataset with images of pizza, steak and sushi.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c9f510a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\pizza_steak_sushi directory exists.\n",
      "Downloading pizza, steak, sushi data...\n",
      "Unzipping pizza, steak, sushi data...\n",
      "Deleted ZIP file after extraction.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import requests\n",
    "\n",
    "# Setup path to data folder\n",
    "DATA_PATH = Path(\"data/\")\n",
    "IMG_PATH = DATA_PATH/ \"pizza_steak_sushi\"\n",
    "ZIP_PATH = DATA_PATH/ \"pizza_steak_sushi.zip\"\n",
    "\n",
    "# If the image folder doesn't exist, download it and prepare it...\n",
    "if IMG_PATH.is_dir():\n",
    "    print(f\"{IMG_PATH} directory exists.\")\n",
    "else:\n",
    "    print(f\"Did not find {IMG_PATH} directory, creating one...\")\n",
    "    IMG_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Download pizza, steak, sushi data\n",
    "with open (ZIP_PATH, 'wb') as f:\n",
    "    req = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
    "    print(\"Downloading pizza, steak, sushi data...\")\n",
    "    f.write(req.content)\n",
    "    \n",
    "# Unzip pizza, steak, sushi data\n",
    "with zipfile.ZipFile(ZIP_PATH, 'r') as zip_ref:\n",
    "    print(\"Unzipping pizza, steak, sushi data...\") \n",
    "    zip_ref.extractall(IMG_PATH)\n",
    "    \n",
    "# Delete the zip file after extraction\n",
    "ZIP_PATH.unlink()\n",
    "print(\"Deleted ZIP file after extraction.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82236139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(WindowsPath('data/pizza_steak_sushi/train'),\n",
       " WindowsPath('data/pizza_steak_sushi/test'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup train and testing paths\n",
    "TRAIN_DIR = IMG_PATH/ \"train\"\n",
    "TEST_DIR = IMG_PATH/ \"test\"\n",
    "\n",
    "TRAIN_DIR, TEST_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b697a982",
   "metadata": {},
   "source": [
    "## 2. Create Datasets and DataLoaders\n",
    "\n",
    "Now we'll turn the image dataset into PyTorch `Dataset`'s and `DataLoader`'s.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2de35971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data:\n",
      "Dataset ImageFolder\n",
      "    Number of datapoints: 225\n",
      "    Root location: data\\pizza_steak_sushi\\train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=(64, 64), interpolation=bilinear, max_size=None, antialias=True)\n",
      "               ToTensor()\n",
      "           )\n",
      "Test data:\n",
      "Dataset ImageFolder\n",
      "    Number of datapoints: 75\n",
      "    Root location: data\\pizza_steak_sushi\\test\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=(64, 64), interpolation=bilinear, max_size=None, antialias=True)\n",
      "               ToTensor()\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Create simple transform\n",
    "data_trans = transforms.Compose([\n",
    "    transforms.Resize((64,64)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Use ImageFolder to create dataset(s)\n",
    "train_dataset = datasets.ImageFolder(TRAIN_DIR,\n",
    "                                    transform= data_trans,\n",
    "                                    target_transform= None)\n",
    "\n",
    "test_dataset = datasets.ImageFolder(TEST_DIR,\n",
    "                                    transform=data_trans)\n",
    "\n",
    "print(f\"Train data:\\n{train_dataset}\\nTest data:\\n{test_dataset}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bd640da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x1c72f0792d0>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x1c72f079930>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn train and test Datasets into DataLoaders\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                        batch_size=1,\n",
    "                        num_workers=1,\n",
    "                        shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                        batch_size=1,\n",
    "                        num_workers=1,\n",
    "                        shuffle=False)\n",
    "\n",
    "train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f6adb6",
   "metadata": {},
   "source": [
    "### 2.1 Create Datasets and DataLoaders (script mode)\n",
    "\n",
    "Rather than rewriting all of the code above everytime we wanted to load data, we can turn it into a script called `data_setup.py`.\n",
    "\n",
    "Let's capture all of the above functionality into a function called `create_dataloaders()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f756d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting going_modular/data_setup.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile going_modular/data_setup.py\n",
    "\"\"\"\n",
    "Contains functionality for creating PyTorch DataLoaders for \n",
    "image classification data.\n",
    "\"\"\"\n",
    "\n",
    "import os \n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "NUM_WORKERS = os.cpu_count()\n",
    "\n",
    "def create_dataloader( \n",
    "    train_dir: str,\n",
    "    test_dir: str,\n",
    "    transform: transforms.Compose,\n",
    "    batch_size: int,\n",
    "    num_workers: int = NUM_WORKERS,\n",
    "    transform_test: transforms.Compose = None\n",
    "):\n",
    "    \"\"\"Creates training and testing DataLoaders.\n",
    "\n",
    "    Takes in a training directory and testing directory path and turns\n",
    "    them into PyTorch Datasets and then into PyTorch DataLoaders.\n",
    "\n",
    "    Args:\n",
    "    train_dir: Path to training directory.\n",
    "    test_dir: Path to testing directory.\n",
    "    transform: torchvision transforms to perform on training and testing data.\n",
    "    batch_size: Number of samples per batch in each of the DataLoaders.\n",
    "    num_workers: An integer for number of workers per DataLoader.\n",
    "    transform_test (optional): specific transform for test dataset.\n",
    "    \n",
    "    Returns:\n",
    "    A tuple of (train_dataloader, test_dataloader, class_names).\n",
    "    Where class_names is a list of the target classes.\n",
    "    Example usage:\n",
    "        train_dataloader, test_dataloader, class_names = \\\n",
    "        = create_dataloaders(train_dir=path/to/train_dir,\n",
    "                                test_dir=path/to/test_dir,\n",
    "                                transform=some_transform,\n",
    "                                batch_size=32,\n",
    "                                num_workers=4)\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1) Use ImageFolder to create dataset(s)\n",
    "    train_dataset = datasets.ImageFolder(train_dir,\n",
    "                                        transform= transform,\n",
    "                                        target_transform= None)\n",
    "\n",
    "    test_dataset = datasets.ImageFolder(test_dir,\n",
    "                                        transform= transform_test if transform_test else transform)\n",
    "    \n",
    "    # 2) Get class_names\n",
    "    class_names = train_dataset.classes\n",
    "    \n",
    "    # 3) Turn train and test Datasets into DataLoaders\n",
    "    train_loader = DataLoader(train_dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            num_workers=num_workers,\n",
    "                            shuffle=True,\n",
    "                            pin_memory=True)\n",
    "\n",
    "    test_loader = DataLoader(test_dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            num_workers=num_workers,\n",
    "                            shuffle=False,\n",
    "                            pin_memory=True)\n",
    "    \n",
    "    return train_loader, test_loader, class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4500fad0",
   "metadata": {},
   "source": [
    "## 3. Making a model (TinyVGG)\n",
    "\n",
    "We're going to use the same model we used in notebook 04: TinyVGG from the CNN Explainer website.\n",
    "\n",
    "The only change here from notebook 04 is that a docstring has been added using [Google's Style Guide for Python](https://google.github.io/styleguide/pyguide.html#384-classes).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a752eb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class TinyVGG (nn.Module):\n",
    "    \"\"\"Creates the TinyVGG architecture.\n",
    "\n",
    "    Replicates the TinyVGG architecture from the CNN explainer website in PyTorch.\n",
    "    See the original architecture here: https://poloclub.github.io/cnn-explainer/\n",
    "\n",
    "    Args:\n",
    "    input_shape: An integer indicating number of input channels.\n",
    "    hidden_units: An integer indicating number of hidden units between layers.\n",
    "    output_shape: An integer indicating number of output units.\n",
    "    \"\"\"\n",
    "    def __init__ (self, input_shape, hidden_units, output_shape):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels= input_shape,\n",
    "                    out_channels= hidden_units,\n",
    "                    \n",
    "                    kernel_size= 3,\n",
    "                    padding=1,\n",
    "                    stride=1),\n",
    "            \n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(in_channels= hidden_units,\n",
    "                    out_channels= hidden_units,\n",
    "                    \n",
    "                    kernel_size= 3,\n",
    "                    padding=1,\n",
    "                    stride=1),\n",
    "            \n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels= hidden_units,\n",
    "                    out_channels= hidden_units,\n",
    "                    \n",
    "                    kernel_size= 3,\n",
    "                    padding=1,\n",
    "                    stride=1),\n",
    "            \n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(in_channels= hidden_units,\n",
    "                    out_channels= hidden_units,\n",
    "                    \n",
    "                    kernel_size= 3,\n",
    "                    padding=1,\n",
    "                    stride=1),\n",
    "            \n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # This ensures the dummy input matches the input shape expected by the model.\n",
    "            temp = torch.zeros(1, input_shape, 64, 64)\n",
    "            dummy = self.conv_block2(self.conv_block1(temp))\n",
    "            num_features = dummy.shape[1] * dummy.shape[2] * dummy.shape[3]\n",
    "            \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            \n",
    "            nn.Linear(in_features= num_features,\n",
    "                    out_features= output_shape)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.classifier(self.conv_block2(self.conv_block1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ad558fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TinyVGG(\n",
       "  (conv_block1): Sequential(\n",
       "    (0): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv_block2): Sequential(\n",
       "    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=2560, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Instantiate an instance of the model\n",
    "torch.manual_seed(42)\n",
    "model_0 = TinyVGG(input_shape=3, # number of color channels (3 for RGB) \n",
    "                hidden_units=10, \n",
    "                output_shape=len(train_dataset.classes)).to(device)\n",
    "model_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9d1dd56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single image shape: torch.Size([1, 3, 64, 64])\n",
      "\n",
      "Output logits:\n",
      "tensor([[0.0578, 0.0634, 0.0351]], device='cuda:0')\n",
      "\n",
      "Output prediction probabilities:\n",
      "tensor([[0.3352, 0.3371, 0.3277]], device='cuda:0')\n",
      "\n",
      "Output prediction label:\n",
      "tensor([1], device='cuda:0')\n",
      "\n",
      "Actual label:\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# 1. Get a batch of images and labels from the DataLoader\n",
    "img_batch, label_batch = next(iter(train_loader))\n",
    "\n",
    "# 2. Get a single image from the batch and unsqueeze the image so its shape fits the model\n",
    "img_single, label_single = img_batch[0].unsqueeze(dim=0), label_batch[0]\n",
    "print(f\"Single image shape: {img_single.shape}\\n\")\n",
    "\n",
    "# 3. Perform a forward pass on a single image\n",
    "model_0.eval()\n",
    "with torch.inference_mode():\n",
    "    pred = model_0(img_single.to(device))\n",
    "    \n",
    "# 4. Print out what's happening and convert model logits -> pred probs -> pred label\n",
    "print(f\"Output logits:\\n{pred}\\n\")\n",
    "print(f\"Output prediction probabilities:\\n{torch.softmax(pred, dim=1)}\\n\")\n",
    "print(f\"Output prediction label:\\n{torch.argmax(torch.softmax(pred, dim=1), dim=1)}\\n\")\n",
    "print(f\"Actual label:\\n{label_single}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4061dc09",
   "metadata": {},
   "source": [
    "### 3.1 Making a model (TinyVGG) (script mode)\n",
    "\n",
    "Over the past few notebooks (notebook 03 and notebook 04), we've built the TinyVGG model a few times.\n",
    "\n",
    "So it makes sense to put the model into its file so we can reuse it again and again.\n",
    "\n",
    "Let's put our `TinyVGG()` model class into a script called `model_builder.py` with the line `%%writefile going_modular/model_builder.py`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "952bd1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting going_modular/model_builder.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile going_modular/model_builder.py\n",
    "\"\"\"\n",
    "Contains PyTorch model code to instantiate a TinyVGG model.\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class TinyVGG(nn.Module):\n",
    "    \"\"\"Creates the TinyVGG architecture.\n",
    "\n",
    "    Replicates the TinyVGG architecture from the CNN explainer website in PyTorch.\n",
    "    See the original architecture here: https://poloclub.github.io/cnn-explainer/\n",
    "\n",
    "    Args:\n",
    "        input_shape (int): Number of input channels (e.g., 3 for RGB images).\n",
    "        hidden_units (int): Number of output channels (filters) for convolutional layers.\n",
    "        output_shape (int): Number of output classes for classification.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_shape: int,\n",
    "                hidden_units: int,\n",
    "                output_shape: int):\n",
    "        super().__init__()\n",
    "\n",
    "        # First convolutional block\n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            # First convolution layer\n",
    "            nn.Conv2d(\n",
    "                in_channels=input_shape,\n",
    "                out_channels=hidden_units,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1  # preserve spatial size\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # Second convolution layer\n",
    "            nn.Conv2d(\n",
    "                in_channels=hidden_units,\n",
    "                out_channels=hidden_units,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # Downsample feature map (halves height and width)\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "\n",
    "        # Second convolutional block\n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=hidden_units,\n",
    "                out_channels=hidden_units,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(\n",
    "                in_channels=hidden_units,\n",
    "                out_channels=hidden_units,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "\n",
    "        # Automatically calculate the number of features going into the linear layer\n",
    "        with torch.no_grad():\n",
    "            # Simulate a dummy input tensor to pass through the conv layers\n",
    "            temp = torch.zeros(1, input_shape, 64, 64)  # batch size 1, 64x64 image\n",
    "            dummy = self.conv_block2(self.conv_block1(temp))\n",
    "            num_features = dummy.shape[1] * dummy.shape[2] * dummy.shape[3]  # flatten dims\n",
    "\n",
    "        # Final classification layer\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),  # Flatten 3D feature map to 1D vector\n",
    "            nn.Linear(\n",
    "                in_features=num_features,\n",
    "                out_features=output_shape  # One output per class\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Defines the forward pass of the network.\"\"\"\n",
    "        # Pass input through both convolutional blocks and the classifier\n",
    "        return self.classifier(self.conv_block2(self.conv_block1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6eb678bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TinyVGG(\n",
       "  (conv_block1): Sequential(\n",
       "    (0): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv_block2): Sequential(\n",
       "    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=2560, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from going_modular import model_builder\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model_1 = model_builder.TinyVGG(input_shape= 3,\n",
    "                                hidden_units=10,\n",
    "                                output_shape= len(train_dataset.classes)).to(device)\n",
    "\n",
    "model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "806390c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single image shape: torch.Size([1, 3, 64, 64])\n",
      "\n",
      "Output logits:\n",
      "tensor([[ 0.0352, -0.0059,  0.0215]], device='cuda:0')\n",
      "\n",
      "Output prediction probabilities:\n",
      "tensor([[0.3394, 0.3258, 0.3348]], device='cuda:0')\n",
      "\n",
      "Output prediction label:\n",
      "tensor([0], device='cuda:0')\n",
      "\n",
      "Actual label:\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# 1. Get a batch of images and labels from the DataLoader\n",
    "img_batch, label_batch = next(iter(train_loader))\n",
    "\n",
    "# 2. Get a single image from the batch and unsqueeze the image so its shape fits the model\n",
    "img_single, label_single = img_batch[0].unsqueeze(dim=0), label_batch[0]\n",
    "print(f\"Single image shape: {img_single.shape}\\n\")\n",
    "\n",
    "# 3. Perform a forward pass on a single image\n",
    "model_1.eval()\n",
    "with torch.inference_mode():\n",
    "    pred = model_1(img_single.to(device))\n",
    "    \n",
    "# 4. Print out what's happening and convert model logits -> pred probs -> pred label\n",
    "print(f\"Output logits:\\n{pred}\\n\")\n",
    "print(f\"Output prediction probabilities:\\n{torch.softmax(pred, dim=1)}\\n\")\n",
    "print(f\"Output prediction label:\\n{torch.argmax(torch.softmax(pred, dim=1), dim=1)}\\n\")\n",
    "print(f\"Actual label:\\n{label_single}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cf1023",
   "metadata": {},
   "source": [
    "## 4. Creating `train_step()` and `test_step()` functions and `train()` to combine them\n",
    "\n",
    "Rather than writing them again, we can reuse the `train_step()` and `test_step()` functions from [notebook 04](https://www.learnpytorch.io/04_pytorch_custom_datasets/#75-create-train-test-loop-functions).\n",
    "\n",
    "The same goes for the `train()` function we created.\n",
    "\n",
    "The only difference here is that these functions have had docstrings added to them in [Google's Python Functions and Methods Style Guide](https://google.github.io/styleguide/pyguide.html#383-functions-and-methods).\n",
    "\n",
    "Let's start by making `train_step()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2883f84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "TinyVGG                                  [1, 3]                    --\n",
       "├─Sequential: 1-1                        [1, 10, 32, 32]           --\n",
       "│    └─Conv2d: 2-1                       [1, 10, 64, 64]           280\n",
       "│    └─ReLU: 2-2                         [1, 10, 64, 64]           --\n",
       "│    └─Conv2d: 2-3                       [1, 10, 64, 64]           910\n",
       "│    └─ReLU: 2-4                         [1, 10, 64, 64]           --\n",
       "│    └─MaxPool2d: 2-5                    [1, 10, 32, 32]           --\n",
       "├─Sequential: 1-2                        [1, 10, 16, 16]           --\n",
       "│    └─Conv2d: 2-6                       [1, 10, 32, 32]           910\n",
       "│    └─ReLU: 2-7                         [1, 10, 32, 32]           --\n",
       "│    └─Conv2d: 2-8                       [1, 10, 32, 32]           910\n",
       "│    └─ReLU: 2-9                         [1, 10, 32, 32]           --\n",
       "│    └─MaxPool2d: 2-10                   [1, 10, 16, 16]           --\n",
       "├─Sequential: 1-3                        [1, 3]                    --\n",
       "│    └─Flatten: 2-11                     [1, 2560]                 --\n",
       "│    └─Linear: 2-12                      [1, 3]                    7,683\n",
       "==========================================================================================\n",
       "Total params: 10,693\n",
       "Trainable params: 10,693\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 6.75\n",
       "==========================================================================================\n",
       "Input size (MB): 0.05\n",
       "Forward/backward pass size (MB): 0.82\n",
       "Params size (MB): 0.04\n",
       "Estimated Total Size (MB): 0.91\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchinfo\n",
    "    \n",
    "from torchinfo import summary\n",
    "summary(model= model_0,\n",
    "        input_size=[1, 3, 64, 64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfb075fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Machine Learning\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from typing import Tuple\n",
    "import torchmetrics \n",
    "\n",
    "def train_step (model: torch.nn.Module,\n",
    "                dataloader: torch.utils.data.DataLoader,\n",
    "                loss_fn: torch.nn.Module ,\n",
    "                acc_fn: torchmetrics.Accuracy,\n",
    "                optimizer: torch.optim.Optimizer,\n",
    "                device: torch.device) -> Tuple[float, float]:\n",
    "    \n",
    "    \"\"\"Trains a PyTorch model for a single epoch.\n",
    "\n",
    "    Turns a target PyTorch model to training mode and then\n",
    "    runs through all of the required training steps (forward\n",
    "    pass, loss calculation, optimizer step).\n",
    "\n",
    "    Args:\n",
    "    model: A PyTorch model to be trained.\n",
    "    dataloader: A DataLoader instance for the model to be trained on.\n",
    "    loss_fn: A PyTorch loss function to minimize.\n",
    "    optimizer: A PyTorch optimizer to help minimize the loss function.\n",
    "    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
    "\n",
    "    Returns:\n",
    "    A tuple of training loss and training accuracy metrics.\n",
    "    In the form (train_loss, train_accuracy). For example:\n",
    "\n",
    "    (0.1112, 0.8743)\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    loss_total, acc_total = 0,0\n",
    "    \n",
    "    for batch, (x, y) in enumerate(dataloader):\n",
    "        x,y = x.to(device), y.to(device)\n",
    "\n",
    "        y_pred = model (x)\n",
    "        \n",
    "        loss = loss_fn(y_pred, y)\n",
    "        loss_total += int(loss)\n",
    "        acc_fn.update(y_pred.argmax(dim=1), y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "    # Calculate loss and accuracy per epoch and print out what's happening\n",
    "    loss_total /= len(dataloader)\n",
    "    acc_total = acc_fn.compute().item()\n",
    "    acc_total *= 100\n",
    "    acc_fn.reset()  \n",
    "    \n",
    "    return loss_total, acc_total   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04b85a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics \n",
    "\n",
    "def test_step ( model: torch.nn.Module,\n",
    "                dataloader: torch.utils.data.DataLoader,\n",
    "                loss_fn: torch.nn.Module ,\n",
    "                acc_fn: torchmetrics.Accuracy,\n",
    "                device: torch.device) -> Tuple[float, float]:\n",
    "    \n",
    "    \"\"\"Tests a PyTorch model for a single epoch.\n",
    "\n",
    "    Turns a target PyTorch model to \"eval\" mode and then performs\n",
    "    a forward pass on a testing dataset.\n",
    "\n",
    "    Args:\n",
    "    model: A PyTorch model to be tested.\n",
    "    dataloader: A DataLoader instance for the model to be tested on.\n",
    "    loss_fn: A PyTorch loss function to calculate loss on the test data.\n",
    "    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
    "\n",
    "    Returns:\n",
    "    A tuple of testing loss and testing accuracy metrics.\n",
    "    In the form (test_loss, test_accuracy). For example:\n",
    "\n",
    "    (0.0223, 0.8985)\n",
    "    \"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    loss_total, acc_total = 0,0\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        for batch, (x, y) in enumerate(dataloader):\n",
    "            x,y = x.to(device), y.to(device)\n",
    "\n",
    "            y_pred = model (x)\n",
    "            \n",
    "            loss = loss_fn(y_pred, y)\n",
    "            loss_total += int(loss)\n",
    "            acc_fn.update(y_pred.argmax(dim=1), y)\n",
    "        \n",
    "    # Calculate loss and accuracy per epoch and print out what's happening\n",
    "    loss_total /= len(dataloader)\n",
    "    acc_total = acc_fn.compute().item()\n",
    "    acc_total *= 100\n",
    "    acc_fn.reset()  \n",
    "    \n",
    "    return loss_total, acc_total    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec7fc217",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from torchmetrics import Accuracy\n",
    "import torch\n",
    "from typing import Dict, List\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# 1. Take in various parameters required for training and test steps\n",
    "def train(model: torch.nn.Module, \n",
    "        train_dataloader: torch.utils.data.DataLoader, \n",
    "        test_dataloader: torch.utils.data.DataLoader, \n",
    "        \n",
    "        optimizer: torch.optim.Optimizer,\n",
    "        loss_fn: torch.nn.Module = nn.CrossEntropyLoss(),\n",
    "        \n",
    "        epochs: int = 5,\n",
    "        device: torch.device = 'cpu') -> Dict[str, List[float]]:\n",
    "    \n",
    "    \"\"\"Trains and tests a PyTorch model.\n",
    "\n",
    "    Passes a target PyTorch models through train_step() and test_step()\n",
    "    functions for a number of epochs, training and testing the model\n",
    "    in the same epoch loop.\n",
    "\n",
    "    Calculates, prints and stores evaluation metrics throughout.\n",
    "\n",
    "    Args:\n",
    "    model: A PyTorch model to be trained and tested.\n",
    "    train_dataloader: A DataLoader instance for the model to be trained on.\n",
    "    test_dataloader: A DataLoader instance for the model to be tested on.\n",
    "    optimizer: A PyTorch optimizer to help minimize the loss function.\n",
    "    loss_fn: A PyTorch loss function to calculate loss on both datasets.\n",
    "    epochs: An integer indicating how many epochs to train for.\n",
    "    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
    "\n",
    "    Returns:\n",
    "    A dictionary of training and testing loss as well as training and\n",
    "    testing accuracy metrics. Each metric has a value in a list for \n",
    "    each epoch.\n",
    "    In the form: {train_loss: [...],\n",
    "                    train_acc: [...],\n",
    "                    test_loss: [...],\n",
    "                    test_acc: [...]} \n",
    "    For example if training for epochs=2: \n",
    "                    {train_loss: [2.0616, 1.0537],\n",
    "                    train_acc: [0.3945, 0.3945],\n",
    "                    test_loss: [1.2641, 1.5706],\n",
    "                    test_acc: [0.3400, 0.2973]} \n",
    "    \"\"\"\n",
    "    \n",
    "    acc_fn = Accuracy(task=\"multiclass\", num_classes=3).to(device)\n",
    "    \n",
    "    # 2. Create empty results dictionary\n",
    "    results = {\"train_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"test_loss\": [],\n",
    "        \"test_acc\": []\n",
    "    }\n",
    "    \n",
    "    # 3. Loop through training and testing steps for a number of epochs\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss, train_acc = train_step(model=model,\n",
    "                                        dataloader=train_dataloader,\n",
    "                                        loss_fn=loss_fn,\n",
    "                                        optimizer=optimizer,\n",
    "                                        acc_fn = acc_fn,\n",
    "                                        device= device)\n",
    "        test_loss, test_acc = test_step(model=model,\n",
    "            dataloader=test_dataloader,\n",
    "            loss_fn=loss_fn,\n",
    "            acc_fn= acc_fn,\n",
    "            device= device)\n",
    "        \n",
    "        # 4. Print out what's happening\n",
    "        print(\n",
    "            f\"Epoch: {epoch+1} | \"\n",
    "            f\"train_loss: {train_loss:.4f} | \"\n",
    "            f\"train_acc: {train_acc:.4f} | \"\n",
    "            f\"test_loss: {test_loss:.4f} | \"\n",
    "            f\"test_acc: {test_acc:.4f}\"\n",
    "        )\n",
    "\n",
    "        # 5. Update results dictionary\n",
    "        # Ensure all data is moved to CPU and converted to float for storage\n",
    "        results[\"train_loss\"].append(train_loss.item() if isinstance(train_loss, torch.Tensor) else train_loss)\n",
    "        results[\"train_acc\"].append(train_acc.item() if isinstance(train_acc, torch.Tensor) else train_acc)\n",
    "        results[\"test_loss\"].append(test_loss.item() if isinstance(test_loss, torch.Tensor) else test_loss)\n",
    "        results[\"test_acc\"].append(test_acc.item() if isinstance(test_acc, torch.Tensor) else test_acc)\n",
    "\n",
    "    # 6. Return the filled results at the end of the epochs\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317845b2",
   "metadata": {},
   "source": [
    "### 4.1 Creating `train_step()` and `test_step()` functions and `train()` to combine them (script mode)   \n",
    "\n",
    "To create a script for `train_step()`, `test_step()` and `train()`, we'll combine their code all into a single cell.\n",
    "\n",
    "We'll then write that cell to a file called `engine.py` because these functions will be the \"engine\" of our training pipeline.\n",
    "\n",
    "We can do so with the magic line `%%writefile going_modular/engine.py`.\n",
    "\n",
    "We'll also make sure to put all the imports we need (`torch`, `typing`, and `tqdm`) at the top of the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "003a104c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting going_modular/engine.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile going_modular/engine.py\n",
    "\"\"\"\n",
    "Contains functions for training and testing a PyTorch model.\n",
    "\"\"\"\n",
    "\n",
    "from typing import Dict, Tuple, List\n",
    "import torch \n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm\n",
    "import torchmetrics\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "\n",
    "# ------------------------ TRAINING STEP ------------------------\n",
    "def train_step(model: torch.nn.Module,\n",
    "               dataloader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               acc_fn: torchmetrics.Accuracy,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               device: torch.device) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Trains a PyTorch model for a single epoch.\n",
    "\n",
    "    Args:\n",
    "        model: A PyTorch model to be trained.\n",
    "        dataloader: A DataLoader providing batches of training data.\n",
    "        loss_fn: The loss function used for optimization (e.g., CrossEntropyLoss).\n",
    "        acc_fn: A torchmetrics Accuracy instance to track accuracy.\n",
    "        optimizer: An optimizer instance (e.g., SGD, Adam).\n",
    "        device: The device to run computations on (CPU or CUDA).\n",
    "\n",
    "    Returns:\n",
    "        Tuple of average training loss and accuracy over the epoch.\n",
    "    \"\"\"\n",
    "    model.train()  # Set model to training mode\n",
    "    loss_total, acc_total = 0, 0\n",
    "\n",
    "    # Loop over training batches\n",
    "    for batch, (x, y) in enumerate(dataloader):\n",
    "        # Move input and target to the target device\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        # Forward pass - get model predictions\n",
    "        y_pred = model(x)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        loss_total += int(loss)\n",
    "\n",
    "        # Update accuracy metric\n",
    "        acc_fn.update(y_pred.argmax(dim=1), y)\n",
    "\n",
    "        # Clear previous gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Backpropagation - calculate gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Update model weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Optional logging every 400 batches\n",
    "        if batch % 400 == 0:\n",
    "            print(f\"Looked at {batch * len(x)}/{len(dataloader.dataset)} samples\")\n",
    "\n",
    "    # Compute average loss and accuracy for the entire epoch\n",
    "    loss_total /= len(dataloader)\n",
    "    acc_total = acc_fn.compute().item() * 100  # Convert to %\n",
    "    acc_fn.reset()  # Reset metric for next epoch\n",
    "\n",
    "    return loss_total, acc_total\n",
    "\n",
    "\n",
    "# ------------------------ TESTING STEP ------------------------\n",
    "def test_step(model: torch.nn.Module,\n",
    "              dataloader: torch.utils.data.DataLoader,\n",
    "              loss_fn: torch.nn.Module,\n",
    "              acc_fn: torchmetrics.Accuracy,\n",
    "              device: torch.device) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Evaluates the model on the test dataset.\n",
    "\n",
    "    Args:\n",
    "        model: A PyTorch model to be evaluated.\n",
    "        dataloader: A DataLoader for test data.\n",
    "        loss_fn: Loss function to evaluate prediction error.\n",
    "        acc_fn: Accuracy metric from torchmetrics.\n",
    "        device: Device to compute on.\n",
    "\n",
    "    Returns:\n",
    "        Tuple of average test loss and accuracy.\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    model.eval()  # Turn off dropout, batchnorm, etc.\n",
    "    loss_total, acc_total = 0, 0\n",
    "\n",
    "    # Disable gradient calculation for inference\n",
    "    with torch.inference_mode():\n",
    "        for batch, (x, y) in enumerate(dataloader):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            # Get predictions\n",
    "            y_pred = model(x)\n",
    "\n",
    "            # Compute loss and update accumulators\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            loss_total += int(loss)\n",
    "            acc_fn.update(y_pred.argmax(dim=1), y)\n",
    "\n",
    "    # Compute epoch-level loss and accuracy\n",
    "    loss_total /= len(dataloader)\n",
    "    acc_total = acc_fn.compute().item() * 100  # Convert to %\n",
    "    acc_fn.reset()  # Reset metric for reuse\n",
    "\n",
    "    return loss_total, acc_total\n",
    "\n",
    "\n",
    "# ------------------------ TRAINING LOOP ------------------------\n",
    "def train(model: torch.nn.Module,\n",
    "          train_dataloader: torch.utils.data.DataLoader,\n",
    "          test_dataloader: torch.utils.data.DataLoader,\n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          loss_fn: torch.nn.Module = nn.CrossEntropyLoss(),\n",
    "          epochs: int = 5,\n",
    "          device: torch.device = 'cpu') -> Dict[str, List[float]]:\n",
    "    \"\"\"\n",
    "    Runs the full training loop: training + testing for multiple epochs.\n",
    "\n",
    "    Args:\n",
    "        model: PyTorch model to train and evaluate.\n",
    "        train_dataloader: DataLoader for training data.\n",
    "        test_dataloader: DataLoader for test data.\n",
    "        optimizer: Optimization algorithm.\n",
    "        loss_fn: Loss function (default = CrossEntropyLoss).\n",
    "        epochs: Total number of epochs to train.\n",
    "        device: Target computation device.\n",
    "\n",
    "    Returns:\n",
    "        Dictionary containing loss and accuracy history for training and testing.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize accuracy metric for classification task\n",
    "    acc_fn = Accuracy(task=\"multiclass\", num_classes=3).to(device)\n",
    "\n",
    "    # Initialize history dictionary for storing results\n",
    "    results = {\n",
    "        \"train_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"test_loss\": [],\n",
    "        \"test_acc\": []\n",
    "    }\n",
    "\n",
    "    # Loop through epochs\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        # Training step\n",
    "        train_loss, train_acc = train_step(\n",
    "            model=model,\n",
    "            dataloader=train_dataloader,\n",
    "            loss_fn=loss_fn,\n",
    "            optimizer=optimizer,\n",
    "            acc_fn=acc_fn,\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "        # Display training results\n",
    "        print(\"\\n\")\n",
    "        print(\"\\033[91m======================================================\\033[0m\")\n",
    "        print(f\"\\033[94mTrain loss: {train_loss:.5f} | Train accuracy: {train_acc:.2f}%\\033[0m\")\n",
    "\n",
    "        # Testing step\n",
    "        test_loss, test_acc = test_step(\n",
    "            model=model,\n",
    "            dataloader=test_dataloader,\n",
    "            loss_fn=loss_fn,\n",
    "            acc_fn=acc_fn,\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "        # Display testing results\n",
    "        print(f\"\\033[92mTest loss: {test_loss:.5f} | Test accuracy: {test_acc:.2f}%\\033[0m\")\n",
    "        print(\"\\033[91m======================================================\\033[0m\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "        # Save results to history (converted to CPU floats if needed)\n",
    "        results[\"train_loss\"].append(train_loss.item() if isinstance(train_loss, torch.Tensor) else train_loss)\n",
    "        results[\"train_acc\"].append(train_acc.item() if isinstance(train_acc, torch.Tensor) else train_acc)\n",
    "        results[\"test_loss\"].append(test_loss.item() if isinstance(test_loss, torch.Tensor) else test_loss)\n",
    "        results[\"test_acc\"].append(test_acc.item() if isinstance(test_acc, torch.Tensor) else test_acc)\n",
    "\n",
    "    # Return metrics for analysis/visualization\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658514d2",
   "metadata": {},
   "source": [
    "## 5. Creating a function to save the model\n",
    "\n",
    "Let's setup a function to save our model to a directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76018fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def save_model(model: torch.nn.Module,\n",
    "                target_dir: str,\n",
    "                model_name: str):\n",
    "    \"\"\"Saves a PyTorch model to a target directory.\n",
    "\n",
    "    Args:\n",
    "    model: A target PyTorch model to save.\n",
    "    target_dir: A directory for saving the model to.\n",
    "    model_name: A filename for the saved model. Should include\n",
    "        either \".pth\" or \".pt\" as the file extension.\n",
    "\n",
    "    Example usage:\n",
    "    save_model(model=model_0,\n",
    "                target_dir=\"models\",\n",
    "                model_name=\"05_going_modular_tingvgg_model.pth\")\n",
    "    \"\"\"\n",
    "    # Create target directory\n",
    "    target_dir_path = Path(target_dir)\n",
    "    target_dir_path.mkdir(parents=True,\n",
    "                        exist_ok=True)\n",
    "\n",
    "    # Create model save path\n",
    "    assert model_name.endswith(\".pth\") or model_name.endswith(\".pt\"), \"model_name should end with '.pt' or '.pth'\"\n",
    "    model_save_path = target_dir_path / model_name\n",
    "\n",
    "    # Save the model state_dict()\n",
    "    print(f\"[INFO] Saving model to: {model_save_path}\")\n",
    "    torch.save(obj=model.state_dict(),\n",
    "                f=model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112bde09",
   "metadata": {},
   "source": [
    "### 5.1 Creating a function to save the model (script mode)\n",
    "\n",
    "How about we add our `save_model()` function to a script called `utils.py` which is short for \"utilities\".\n",
    "\n",
    "We can do so with the magic line `%%writefile going_modular/utils.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb63a4e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting going_modular/utils.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile going_modular/utils.py\n",
    "\"\"\"\n",
    "Contains various utility functions for PyTorch model training and saving.\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "def save_model(model: torch.nn.Module,\n",
    "                target_dir: str,\n",
    "                model_name: str):\n",
    "    \"\"\"\n",
    "    Saves a PyTorch model's state_dict to a specified directory.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The PyTorch model to be saved.\n",
    "        target_dir (str): The directory where the model should be saved.\n",
    "        model_name (str): The name for the saved model file. Should end with '.pt' or '.pth'.\n",
    "\n",
    "    Example:\n",
    "        save_model(model=model_0,\n",
    "                target_dir=\"models\",\n",
    "                model_name=\"05_going_modular_tinyvgg_model.pth\")\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert target_dir to a Path object and create the directory if it doesn't exist\n",
    "    target_dir_path = Path(target_dir)\n",
    "    target_dir_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Check the file extension is valid\n",
    "    assert model_name.endswith(\".pth\") or model_name.endswith(\".pt\"), \\\n",
    "        \"❌ Error: model_name should end with '.pt' or '.pth'\"\n",
    "\n",
    "    # Create the full path to where the model will be saved\n",
    "    model_save_path = target_dir_path / model_name\n",
    "\n",
    "    # Save only the state_dict (recommended for most use cases)\n",
    "    torch.save(obj=model.state_dict(), f=model_save_path)\n",
    "\n",
    "    print(f\"[INFO] ✅ Model saved to: {model_save_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de66561",
   "metadata": {},
   "source": [
    "## 6. Train, evaluate and save the model\n",
    "\n",
    "Let's leverage the functions we've got above to train, test and save a model to file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31236908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Total training time: 0.000 seconds\n",
      "[INFO] Saving model to: models\\05_going_modular_cell_mode_tinyvgg_model.pth\n"
     ]
    }
   ],
   "source": [
    "# Set random seeds\n",
    "torch.manual_seed(42) \n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "# Set number of epochs\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "# Recreate an instance of TinyVGG\n",
    "model_0 = TinyVGG(input_shape=3, # number of color channels (3 for RGB) \n",
    "                    hidden_units=10, \n",
    "                    output_shape=len(train_dataset.classes)).to(device)\n",
    "\n",
    "# Setup loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model_0.parameters(), lr=0.001)\n",
    "\n",
    "# Start the timer\n",
    "from timeit import default_timer as timer \n",
    "start_time = timer()\n",
    "\n",
    "# Train model_0 \n",
    "# model_0_results = train(model=model_0, \n",
    "#                         train_dataloader=train_loader,\n",
    "#                         test_dataloader=test_loader,\n",
    "#                         optimizer=optimizer,\n",
    "#                         loss_fn=loss_fn, \n",
    "#                         epochs=NUM_EPOCHS,\n",
    "#                         device=device)\n",
    "\n",
    "# End the timer and print out how long it took\n",
    "end_time = timer()\n",
    "print(f\"[INFO] Total training time: {end_time-start_time:.3f} seconds\")\n",
    "\n",
    "# Save the model\n",
    "save_model(model=model_0,\n",
    "            target_dir=\"models\",\n",
    "            model_name=\"05_going_modular_cell_mode_tinyvgg_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba19e00a",
   "metadata": {},
   "source": [
    "### 6.1 Train, evaluate and save the model (script mode)\n",
    "\n",
    "Let's combine all of our modular files into a single script `train.py`.\n",
    "\n",
    "This will allow us to run all of the functions we've written with a single line of code on the command line:\n",
    "\n",
    "`python going_modular/train.py`\n",
    "\n",
    "Or if we're running it in a notebook:\n",
    "\n",
    "`!python going_modular/train.py`\n",
    "\n",
    "We'll go through the following steps:\n",
    "1. Import the various dependencies, namely `torch`, `os`, `torchvision.transforms` and all of the scripts from the `going_modular` directory, `data_setup`, `engine`, `model_builder`, `utils`.\n",
    "  * **Note:** Since `train.py` will be *inside* the `going_modular` directory, we can import the other modules via `import ...` rather than `from going_modular import ...`.\n",
    "2. Setup various hyperparameters such as batch size, number of epochs, learning rate and number of hidden units (these could be set in the future via [Python's `argparse`](https://docs.python.org/3/library/argparse.html)).\n",
    "3. Setup the training and test directories.\n",
    "4. Setup device-agnostic code.\n",
    "5. Create the necessary data transforms.\n",
    "6. Create the DataLoaders using `data_setup.py`.\n",
    "7. Create the model using `model_builder.py`.\n",
    "8. Setup the loss function and optimizer.\n",
    "9. Train the model using `engine.py`.\n",
    "10. Save the model using `utils.py`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b388638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting going_modular/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile going_modular/train.py\n",
    "\"\"\"\n",
    "Trains a PyTorch image classification model using device-agnostic code.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from going_modular import data_setup, engine, model_builder, utils\n",
    "\n",
    "def init(num_epochs: int = 3,\n",
    "        batch_size: int = 32,\n",
    "        hidden_units: int = 10,\n",
    "        learning_rate: float = 0.001,\n",
    "        train_dir: str = \"data/pizza_steak_sushi/train\",\n",
    "        test_dir: str = \"data/pizza_steak_sushi/test\"):\n",
    "    \"\"\"\n",
    "    Initializes training pipeline using modular components.\n",
    "\n",
    "    Args:\n",
    "        num_epochs (int): Number of epochs to train the model.\n",
    "        batch_size (int): Number of samples per batch for training/testing.\n",
    "        hidden_units (int): Number of hidden units in the TinyVGG model.\n",
    "        learning_rate (float): Learning rate for optimizer.\n",
    "        train_dir (str): Path to training data.\n",
    "        test_dir (str): Path to testing data.\n",
    "    \"\"\"\n",
    "\n",
    "    # Setup hyperparameters for easy tracking and reference\n",
    "    HYPER_PARAMS = {\n",
    "        'NUM_EPOCHS': num_epochs,\n",
    "        'BATCH_SIZE': batch_size,\n",
    "        'HIDDEN_UNITS': hidden_units,\n",
    "        'LEARNING_RATE': learning_rate\n",
    "    }\n",
    "\n",
    "    # Detect the device (GPU if available, otherwise CPU)\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    # Define image transforms (resize + convert to tensor)\n",
    "    data_transform = transforms.Compose([\n",
    "        transforms.Resize((64, 64)),  # Resize all images to 64x64\n",
    "        transforms.ToTensor()         # Convert PIL image to PyTorch tensor\n",
    "    ])\n",
    "\n",
    "    # Create training and testing dataloaders\n",
    "    train_dataloader, test_dataloader, class_names = data_setup.create_dataloader(\n",
    "        train_dir=train_dir,\n",
    "        test_dir=test_dir,\n",
    "        transform=data_transform,\n",
    "        batch_size=HYPER_PARAMS[\"BATCH_SIZE\"]\n",
    "    )\n",
    "    print(\"✅ Dataloaders created successfully!\")\n",
    "\n",
    "    # Build the TinyVGG model based on the provided parameters\n",
    "    model = model_builder.TinyVGG(\n",
    "        input_shape=3,  # RGB images\n",
    "        hidden_units=HYPER_PARAMS[\"HIDDEN_UNITS\"],\n",
    "        output_shape=len(class_names)  # Number of classes\n",
    "    ).to(device)\n",
    "    print(\"✅ Model built successfully!\")\n",
    "\n",
    "    # Set up the loss function and optimizer\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(),\n",
    "                                lr=HYPER_PARAMS[\"LEARNING_RATE\"])\n",
    "\n",
    "    # Train and evaluate the model using the engine module\n",
    "    engine.train(\n",
    "        model=model,\n",
    "        train_dataloader=train_dataloader,\n",
    "        test_dataloader=test_dataloader,\n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optimizer,\n",
    "        epochs=HYPER_PARAMS[\"NUM_EPOCHS\"],\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    # Save the trained model using a utility function\n",
    "    utils.save_model(\n",
    "        model=model,\n",
    "        target_dir=\"models\",  # Save directory\n",
    "        model_name=\"05_going_modular_script_mode_tinyvgg_model.pth\"\n",
    "    )\n",
    "    print(\"✅ Model saved successfully!\")\n",
    "\n",
    "# When running the script directly, start training\n",
    "if __name__ == \"__main__\":\n",
    "    init()\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a53d43",
   "metadata": {},
   "source": [
    "Now our final directory structure looks like:\n",
    "```\n",
    "data/\n",
    "  pizza_steak_sushi/\n",
    "    train/\n",
    "      pizza/\n",
    "        train_image_01.jpeg\n",
    "        train_image_02.jpeg\n",
    "        ...\n",
    "      steak/\n",
    "      sushi/\n",
    "    test/\n",
    "      pizza/\n",
    "        test_image_01.jpeg\n",
    "        test_image_02.jpeg\n",
    "        ...\n",
    "      steak/\n",
    "      sushi/\n",
    "going_modular/\n",
    "  data_setup.py\n",
    "  engine.py\n",
    "  model_builder.py\n",
    "  train.py\n",
    "  utils.py\n",
    "models/\n",
    "  saved_model.pth\n",
    "```\n",
    "\n",
    "Now to put it all together!\n",
    "\n",
    "Let's run our `train.py` file from the command line with:\n",
    "\n",
    "```\n",
    "!python going_modular/train.py\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "acef0f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataloaders created successfully!\n",
      "✅ Model built successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looked at 0/225 samples\n",
      "\n",
      "\n",
      "\u001b[91m======================================================\u001b[0m\n",
      "\u001b[94mTrain loss: 1.00000 | Train accuracy: 29.33%\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:36<01:12, 36.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mTest loss: 1.00000 | Test accuracy: 33.33%\u001b[0m\n",
      "\u001b[91m======================================================\u001b[0m\n",
      "\n",
      "\n",
      "Looked at 0/225 samples\n",
      "\n",
      "\n",
      "\u001b[91m======================================================\u001b[0m\n",
      "\u001b[94mTrain loss: 1.00000 | Train accuracy: 34.67%\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [01:14<00:37, 37.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mTest loss: 0.66667 | Test accuracy: 33.33%\u001b[0m\n",
      "\u001b[91m======================================================\u001b[0m\n",
      "\n",
      "\n",
      "Looked at 0/225 samples\n",
      "\n",
      "\n",
      "\u001b[91m======================================================\u001b[0m\n",
      "\u001b[94mTrain loss: 1.00000 | Train accuracy: 34.67%\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [01:55<00:00, 38.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mTest loss: 1.00000 | Test accuracy: 33.33%\u001b[0m\n",
      "\u001b[91m======================================================\u001b[0m\n",
      "\n",
      "\n",
      "[INFO] ✅ Model saved to: models\\05_going_modular_script_mode_tinyvgg_model.pth\n",
      "✅ Model saved successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from going_modular import train\n",
    "\n",
    "train.init()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
