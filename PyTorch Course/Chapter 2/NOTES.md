# Chapter 2 notes:

## [**SLIDES**](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/slides/02_pytorch_classification.pdf)
## [**Book link**](https://www.learnpytorch.io/02_pytorch_classification/)

## The **`make_circles`** function in scikit-learn
it is a utility that helps you generate a synthetic **two-dimensional** dataset where the samples form two concentric circles. This kind of dataset is particularly useful for demonstrating problems where classes aren’t **linearly** separable, and it’s often used to experiment with classification algorithms that can capture non-linear decision boundaries.

Below is a simple breakdown of how **make_circles** works and its key features:

### What It Does
- **Generates Two Circular Patterns:** The function creates points arranged in two circles—one circle is nested inside the other. Each circle represents a different class.
- **Binary Classification Dataset:** It returns a pair (X, y) where:
  - **X** is an array of shape `(n_samples, 2)` containing the coordinates of the points.
  - **y** is an array of labels (typically 0s and 1s) assigning each point to one of the two circles.

### Key Parameters
- **n_samples:**  
  This determines the total number of points generated. You can also supply an integer or a tuple specifying the distribution of points between the two circles.
  
- **noise:**  
  A parameter that controls the amount of Gaussian noise added to the data. Increasing the noise value makes the circles less perfect and more challenging for a classifier to separate.
  
- **factor:**  
  This scales the size of the inner circle relative to the outer circle. A value between 0 and 1 specifies how much smaller the inner circle should be compared to the outer one.
  
- **random_state:**  
  A seed value to ensure that the generated dataset is reproducible. When set, the same random samples are produced across different runs.

### Why Use make_circles?
- **Demonstrating Non-Linear Separation:**  
  Linear classifiers (like logistic regression or linear SVM) typically struggle with this dataset because the classes cannot be separated by a straight line. Therefore, it is ideal for illustrating the need for non-linear decision boundaries.
  
- **Testing Algorithms:**  
  It provides a controlled environment to test and visualize algorithms, especially those that employ kernel tricks (like the kernel SVM) or neural networks, which are capable of handling non-linear data distributions.
  
### A Simple Example in Code

```python
from sklearn.datasets import make_circles
import matplotlib.pyplot as plt

# Generate the dataset
X, y = make_circles(n_samples=300, noise=0.05, factor=0.5, random_state=42)

# Plotting the circles
plt.scatter(X[:, 0], X[:, 1], c=y, cmap='viridis')
plt.title("Two Concentric Circles Dataset")
plt.xlabel("Feature 1")
plt.ylabel("Feature 2")
plt.show()
```

In this example:
- **n_samples=300** creates 300 points.
- **noise=0.05** adds a small amount of randomness to the points’ positions.
- **factor=0.5** means the inner circle’s radius is half that of the outer circle.
- **random_state=42** ensures reproducibility.

---

When you see the descriptions for **X** and **y** in the context of **make_circles** (or many other dataset functions in scikit-learn), they refer to two fundamental components of a dataset used in machine learning:

### X: The Feature Array
- **Shape:** When it states that *X is an array of shape (n_samples, 2)*, this means that **X** is organized as a matrix where:
  - **n_samples:** This is the number of data points (or samples) generated by the function.
  - **2:** This number indicates that each data point has two features (or dimensions). In the case of make_circles, these two features represent the **x** and **y** coordinates of a point in a two-dimensional space.
- **Content:** Every row in **X** corresponds to a specific point in the dataset. For instance, a row `[0.5, 1.2]` means that there is a point located at the x-coordinate 0.5 and the y-coordinate 1.2.

### y: The Label Array
- **Content:** The array **y** contains the class labels for each corresponding row in **X**. 
  - Typically, in the make_circles dataset, **y** consists of binary labels (0s and 1s).
  - A label like **0** might be assigned to points belonging to one circle (say the outer circle), and a label like **1** to points belonging to the other circle (the inner circle).
- **Usage:** These labels are what you would use in a classification task to train a model to distinguish between the points on the two different circles.

### How They Work Together
- **Pairing:** Each sample in **X** is paired with a label from **y**. If you have a dataset with `n_samples = 300`, then:
  - **X** would have 300 rows (each with 2 numerical values).
  - **y** would have 300 labels (each being either 0 or 1).
- **Example:** Suppose your dataset generated by `make_circles` produces a row in **X** like `[0.8, 0.6]` and the corresponding index in **y** is `0`. This tells you that the point at coordinates `(0.8, 0.6)` belongs to the class labeled `0`, which could be the outer circle.

### Why This Matters
- **Learning Task:** In machine learning, you use **X** as the input data (features) for training your model, and **y** as the target variable (labels) that the model will learn to predict.
- **Visualization & Analysis:** You can plot the points based on their coordinates in **X**, and color-code them according to their labels in **y** to visually inspect the distribution and see how well separated the classes are.

This structure of having an array of features and a corresponding array of labels is very common in supervised learning problems, and functions like **make_circles** provide a simple way to generate such synthetic datasets for experimentation and demonstrations.
